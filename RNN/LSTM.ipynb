{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "664871d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary tools\n",
    "from tensorflow.keras.models import Sequential  # Basic neural network container\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense  # Layers we'll use\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # For text handling\n",
    "from tensorflow.keras.utils import pad_sequences  # To make sequences same length\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4128fb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"I loved this movie\", \"Hated the film\", \"Best movie ever\", \"Worst experience\"] \n",
    "labels = np.array([1, 0, 1, 0])  # 1=positive, 0=negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfb41293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare the text data\n",
    "tokenizer = Tokenizer(num_words=10000)  # Keep top 10,000 words\n",
    "tokenizer.fit_on_texts(texts)  # Learn all words in our texts\n",
    "sequences = tokenizer.texts_to_sequences(texts)  # Convert words to numbers\n",
    "data = pad_sequences(sequences, maxlen=100)  # Make all reviews 100 words long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcdff266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build the model\n",
    "model = Sequential()  # Create empty model\n",
    "\n",
    "# Add layers one by one:\n",
    "# 1. Embedding: Turns word numbers into meaningful vectors\n",
    "model.add(Embedding(input_dim=10000,  # How many unique words we have\n",
    "                   output_dim=128))    # Size of each word vector\n",
    "\n",
    "# 2. LSTM layer: Understands sequences in the text\n",
    "model.add(LSTM(units=64))  # 64 memory units\n",
    "\n",
    "# 3. Dense layer: Final decision maker (positive/negative)\n",
    "model.add(Dense(1, activation='sigmoid'))  # 1 output: 0-1 probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c0a83b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',       # Smart learning algorithm\n",
    "              loss='binary_crossentropy',  # How to measure errors\n",
    "              metrics=['accuracy'])   # Track correct guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "686d1337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.2500 - loss: 0.6937\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7500 - loss: 0.6852\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.6767\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.6682\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.6594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ec1020c890>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Train the model\n",
    "model.fit(data, labels,  # Our prepared data and answers\n",
    "          epochs=5,      # How many times to see all data\n",
    "          batch_size=32) # Process 32 reviews at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aeb72d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.48232335]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the model can predict sentiments!\n",
    "test_text = [\"This film was okay\"]\n",
    "test_seq = tokenizer.texts_to_sequences(test_text)\n",
    "test_data = pad_sequences(test_seq, maxlen=100)\n",
    "prediction = model.predict(test_data)  # Returns something like [[0.65]] (65% positive)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c52acdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.48232335]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the model can predict sentiments!\n",
    "test_text = [\"This film was horrible\"]\n",
    "test_seq = tokenizer.texts_to_sequences(test_text)\n",
    "test_data = pad_sequences(test_seq, maxlen=100)\n",
    "prediction = model.predict(test_data)  # Returns something like [[0.65]] (65% positive)\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
